#include "gelu_backward_metax.h"
#include "../../../elementwise/metax/elementwise_metax.h"
#include "../cuda/kernel.cuh"
namespace op::gelu_backward::metax {

Descriptor::~Descriptor() = default;

infiniStatus_t Descriptor::create(
    infiniopHandle_t handle_,
    Descriptor **desc_ptr,
    infiniopTensorDescriptor_t out_desc,
    std::vector<infiniopTensorDescriptor_t> input_desc_vec
) {

    auto handle = reinterpret_cast<device::metax::Handle *>(handle_);
//  --------------------- start: check data type and calculate workspace size ---------------------- 
    auto dtype = out_desc->dtype();
    const auto &x_desc = input_desc_vec.at(0);
    const auto &grad_y_desc = input_desc_vec.at(1);
    CHECK_DTYPE(dtype, INFINI_DTYPE_F16, INFINI_DTYPE_F32, INFINI_DTYPE_BF16);
    CHECK_SAME_SHAPE(out_desc->shape(), x_desc->shape(), grad_y_desc->shape());
//  ---------------------- end: check data type and calculate workspace size -----------------------
    // create CUDA elementwise descriptor
    CREATE_ELEMENTWISE_METAX_DESCRIPTOR(handle, dtype, out_desc, input_desc_vec)

    return INFINI_STATUS_SUCCESS;
}

infiniStatus_t Descriptor::calculate(
    void *workspace,
    size_t workspace_size,
    void *output,
    std::vector<const void *> inputs,
    void *stream
) const {

    if (workspace_size < _workspace_size) {
        return INFINI_STATUS_INSUFFICIENT_WORKSPACE;
    }

    #define CALCULATE_GELU_BACKWARD_OP(BLOCK_SIZE, TDATA) \
        return _device_info->calculate<BLOCK_SIZE, cuda::GeLUBackwardOp, TDATA>(_info, workspace, output, inputs, stream);

    switch (_dtype) {
    case INFINI_DTYPE_F16:
        CALCULATE_GELU_BACKWARD_OP(256, half)
    case INFINI_DTYPE_BF16:
        CALCULATE_GELU_BACKWARD_OP(256, cuda_bfloat16)
    case INFINI_DTYPE_F32:
        CALCULATE_GELU_BACKWARD_OP(256, float)
    default:
        return INFINI_STATUS_BAD_TENSOR_DTYPE;
    }
    #undef CALCULATE_GELU_BACKWARD_OP 

    return INFINI_STATUS_SUCCESS;
}
} // namespace op::gelu_backward::metax
